\section{Variables Aleatorias}
\begin{enumerate}
	\setcounter{enumi}{15}
	\item
		Definición: $F_X(x)$ es la función que en cada punto vale $P(X\leq x)$.
		
		Propiedades:
			\begin{enumerate}
				\item $0 \leq F_X(x) \leq 1$
				\item Es creciente: $x< y \Rightarrow F_X(x) \leq F_X(y)$
				\item $\lim_{x\rightarrow -\infty}F_X(x) = 0$ y $\lim_{x\rightarrow +\infty}F_X(x) = 1$
				\item $F_X$ es continua a derecha.
			\end{enumerate}
			
		Demostraciones:
			\begin{enumerate}
				\item Vale porque en cada punto es una probabilidad.
				\item
					Sean $x,k > 0$. $$F_X(x+k) = P(X\leq x+k) = P((X\leq x) \lor (x<X\leq x+k)) = P(X\leq x) + P(x<X\leq x+k)$$
					porque ambos eventos son disjuntos. Luego $$F_X(x+k) = F_X(x) + P(x<X\leq x+k) \geq F_X(x)$$
				\item
					Empezamos por demostrar que $\lim_{x \rightarrow +\infty}F_X(x) = 1$.
					
					Sea $\{A_n\}$ una sucesión de eventos tal que $A_n = \{X\leq n\}$.
					Esta es una sucesión creciente (o sea que $A_n \subset A_{n+1}$), y además $\lim_{n\rightarrow +\infty}A_n = \{x \in\mathbb{R}\}$.
					
					$$\lim_{n\rightarrow +\infty}F_X(n) = \lim_{n\rightarrow +\infty}P(A_n) = P(\{x\in\mathbb{R}\}) = 1$$
					el segundo paso se puede hacer porque la sucesión es creciente.
					
					Ahora vamos a demostrar que $\lim_{x \rightarrow -\infty}F_X(x) = 0$.
					
					Sea $\{A_n\}$ una sucesión de eventos tal que $A_n = \{X\leq -n\}$.
					Esta es una sucesión decreciente (o sea que $A_n \supset A_{n+1}$), y además $\lim_{n\rightarrow +\infty}A_n = \emptyset $.
					
					$$\lim_{n\rightarrow -\infty}F_X(n) = \lim_{n\rightarrow +\infty}P(A_n) = P(\emptyset) = 0$$
					el segundo paso se puede hacer porque la sucesión es decreciente.
				\item
					Queremos ver que, dados $x_0\in\mathbb{R}$, $\epsilon > 0$, existe $\delta > 0$ tal que:
					$$x_0 < x < x_0 + \delta \Rightarrow F_X(x_0) - \epsilon < F_X(x) < F_X(x_0) + \epsilon$$
					
					La primera parte se cumple porque $F_X$ es una función creciente. Queda ver que $F_X(x) < F_X(x_0) + \epsilon$.
					
					Consideramos la sucesión $\{A_n\}$ tal que $A_n = \{X \in (-\infty, x_0 + 1/n]\}$. Sea $A = \{X \in (-\infty, x_0]\}$.
					Esta sucesión es decreciente y además $P(A_n) = F_X(x_0+\frac{1}{n})$.
					
					Además $\lim_{n\rightarrow \infty}A_n = A$
					
					$$\lim_{n\rightarrow \infty}F_X(x_0 + 1/n) = \lim_{n\rightarrow \infty}P(A_n) = P(A) = F_X(x_0)$$
					
					Entonces, como $F_X$ es creciente, dados $x_0, \epsilon$ existe $n_0$ tal que:
					$$n > n_0 \Rightarrow F_X(x_0 + 1/n) < F_X(x_0) + \epsilon$$
					
					Así que tomando $\delta = 1/n_0$ se cumple la condición.
			\end{enumerate}
	\item
		Sea $a = F_X(x_0) - P(X=x_0)$. Queremos ver que dados $x_0, \epsilon > 0$, existe $\delta > 0$ tal que
		$$x_0 - \delta < x < x_0 \Rightarrow a - \epsilon \leq F_X(x) \leq a + \epsilon$$
		
		Al mismo tiempo $a = P(X\leq x_0) - P(X=x_0) = P(X < x_0)$.
		Como $x < x_0$, se cumple que $P(X\leq x) \leq P(X<x_0)$. Entonces:
		$$F_X(x) = P(X\leq x) \leq P(X<x_0) = a$$
		Por lo tanto $F_X(x) \leq a + \epsilon$. Queda ver $a - \epsilon \leq F_X(x)$.
		
		Tomamos $\{A_n\}$ tal que $A_n=\{X < x_0-1/n\}$. Es una sucesión creciente y $\bigcup_{i=1}^{\infty}A_i = \{X<x_0\}$.
		
		Entonces $$\lim_{n\rightarrow\infty}F_X(x_0 - 1/n) = \lim_{n\rightarrow\infty}P(A_n) = P(X < x_0) = a$$
		
		Por lo tanto existe $n_0$ tal que $n>n_0\Rightarrow F_X(x_0 - 1/n_0) \geq a - \epsilon$.
		Como $F_X$ es creciente, tomando $\delta = 1/n_0$ se obtiene la propiedad. 
	\item
		
  % Ej 19 %
	\item
		
    Sean $F_X$, $F_Y$ funciones de distribución acumuladas de X e Y respectivamente.
    
    \begin{itemize}
      \item[$\Rightarrow)$] $P(X = x) = P(Y = x)$ para todo $x$. Sea $x \in R_X$ \\
                            $F_X(x) = P(X \leq x) = \sum_{y \leq x, y \in R_X }^{} P_X(y) =  \sum_{y \leq x, y \in R_X }^{} P_Y(y) = F_Y(x) $
      \item[$\Leftarrow)$]  $F_X = F_Y$, para todo $x \in R_X $ vale $F_X(x) = F_Y(x)$. Luego: \\
                            $P(X=x) = F_X(x) - F_X(x^{-}) = F_Y(x) - F_Y(x^{-}) = P(Y=x)$
    \end{itemize}
    
	\item
		Sea $$F(T) = P(N(t) \geq n) = \sum_{k=n}^{\infty}\frac{e^{-\lambda t}(\lambda t)^k}{k!}$$
		
		Queremos ver que esto es la acumulada de una Gamma. Si derivamos por $t$, el objetivo es formar la densidad de una Gamma.
		
		\begin{align*}
			f(t)	& = \sum_{k=n}^{\infty}\frac{e^{-\lambda t}\cdot k(\lambda t)^{k-1}\lambda}{k!} + \sum_{k=n}^{\infty}\frac{(-\lambda)e^{-\lambda t}\cdot(\lambda t)^k}{k!}	\\
					& = \sum_{k=n}^{\infty}\frac{e^{-\lambda t}(\lambda t)^{k-1}\lambda}{(k-1)!} - \sum_{k=n}^{\infty}\frac{\lambda e^{-\lambda t}\cdot(\lambda t)^k}{k!}		\\
					& = e^{-\lambda t} \left(\sum_{k=n}^{\infty}\frac{\lambda^k t^{k-1}}{(k-1)!} - \sum_{k=n}^{\infty}\frac{\lambda^{k+1} t^k}{k!}\right)						\\
					& = e^{-\lambda t} \left(\sum_{k=n-1}^{\infty}\frac{\lambda^{k+1} t^k}{k!} - \sum_{k=n}^{\infty}\frac{\lambda^{k+1} t^k}{k!}\right)						\\
					& = e^{-\lambda t} \frac{\lambda^{n} t^{n-1}}{(n-1)!}	\\
					& = \frac{e^{-\lambda t}\lambda^{n} t^{n-1}}{\Gamma(n)}
		\end{align*}
		
		Que es la densidad de una $\Gamma(n, \lambda)$.
	\item
		Primero, supongamos que $\mu=0$ porque al ser la integral en $(-\infty, +\infty)$ no cambia el valor con un desplazamiento horizontal.
		
		Si llamamos $I$ a la integral que buscamos, vamos a calcular el valor de $I^2$.
		
		\begin{align*}
			I^2	& = \int_{-\infty}^{+\infty} \frac{1}{\sqrt{2\pi \sigma^2}}e^{\frac{-x^2}{2\sigma^2}} dx	\cdot \int_{-\infty}^{+\infty} \frac{1}{\sqrt{2\pi \sigma^2}}e^{\frac{-y^2}{2\sigma^2}} dy	\\
				& = \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} \frac{1}{\sqrt{2\pi \sigma^2}}e^{\frac{-x^2}{2\sigma^2}} \frac{1}{\sqrt{2\pi \sigma^2}}e^{\frac{-y^2}{2\sigma^2}} dy dx			\\
				& = \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} \frac{1}{2\pi \sigma^2} e^{\frac{-(x^2+y^2)}{2\sigma^2}} dy dx
		\end{align*}
		
		Hacemos un cambio a coordenadas polares: $x = r\cdot sin(\theta)$, $y = r\cdot cos(\theta)$.
		\begin{align*}
			I^2	& = \int_{0}^{+\infty} \int_{0}^{2\pi} \frac{1}{2\pi \sigma^2} e^{\frac{-r^2}{2\sigma^2}}\cdot r d\theta dr	\\
				& = \int_{0}^{+\infty} \frac{r}{\sigma^2} e^{\frac{-r^2}{2\sigma^2}} dr										\\
				& =  -e^{\frac{-r^2}{2\sigma^2}}\Big|_{0}^{+\infty} = 0 + e^0 = 1
		\end{align*}
	\item
		Ver ejercicio 40 (es igual)
	\item
		Sea $X\sim E(\lambda)$. Entonces $P(X \geq k) = e^{-\lambda k}$.
		Sean $k>0$, $t>0$.
		\begin{align*}
			P(X \geq k+t | X\geq k)	& = \frac{P(X \geq k+t \land X\geq k)}{P(X\geq k)} = \frac{P(X \geq k+t)}{P(X\geq k)}	\\
									& = \frac{e^{-\lambda (t+k}}{e^{-\lambda k}} = e^{-\lambda (t+k-k)} = e^{-\lambda t} = P(X \geq t)
		\end{align*}
	\item
		Tenemos que:
		$$F_Y(y) = P(Y < y) =  P(X < g^{-1}(y)) = F_X(g^{-1}(y))$$
		Derivando,
		$$f_Y(y) = f_X(g^{-1}(y))\cdot (g^{-1}(y))'$$

	\item
		$X$ se mueve entre $1/2$ y $1$ por cómo está construida.
		\begin{align*}
			F_X(k)	& = P(X \leq k) = P(U\leq k \land 1-U\leq k) = P(1-k \leq U \leq k)	\\
					& = F_U(k) - F_U(1-k) = k - (1-k)									\\
					& = 2k - 1
		\end{align*}
		Siempre que $1/2\leq k\leq 1$.
		
		Derivando, $f_X(x) = 2\cdot \mathbb{I}_{[1/2; 1]}(x)$.
		
		$$E(X) = \int_{1/2}^{1} 2x\text{ }dx = x^2\Big|_{1/2}^{1} = 1-\frac{1}{4} = \frac{3}{4}$$
		
		$$E(X^2) = \int_{1/2}^{1} 2x^2\text{ }dx = \frac{2x^3}{3}\Big|_{1/2}^{1} = \frac{2}{3} - \frac{1}{12} = \frac{7}{12}$$
		
		$$V(X) = E(X^2) - E(X)^2 = \frac{7}{12} - \frac{9}{16} = \frac{1}{48}$$
\end{enumerate}
